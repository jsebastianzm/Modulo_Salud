# -*- coding: utf-8 -*-
"""Limpieza_de_datos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19BaXdYOasVeaBfK4U6IN8a-gkuokSBqP

# Librerias
"""

import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import plotly.express as px
import seaborn as sns
import dtale
import a_funciones as a
pd.set_option('display.max_columns', None)

# from google.colab import drive
# drive.mount('/content/drive')


"""# Cargar base de datos"""

df_cronicos = pd.read_csv('datos\RETO_df_cronicos.csv')
df_egresos = pd.read_csv('datos\RETO_df_egresos.csv')
df_usuarios = pd.read_csv('datos\RETO_df_usuarios.csv')

# df_cronicos = pd.read_csv('/content/drive/MyDrive/Cursos de analitica/Analitica 3/Salud/Datos/RETO_df_cronicos.csv')
# df_egresos = pd.read_csv('/content/drive/MyDrive/Cursos de analitica/Analitica 3/Salud/Datos/RETO_df_egresos.csv')
# df_usuarios = pd.read_csv('/content/drive/MyDrive/Cursos de analitica/Analitica 3/Salud/Datos/RETO_df_usuarios.csv')

df_cronicos.head()

df_egresos.head()

df_usuarios.head()

"""# Información importante!!

Mensualmente, la aseguradora (Nueva EPS) envía un listado de la población perteneciente a la cohorte del mes en curso bajo la modalidad de PGP.
Para la población que hace parte de este contrato se requiere predecir el uso mensual de recursos traducido en hospitalización (estancia hospitalaria) y cirugías de acuerdo con la clase funcional a la que pertenece el paciente.

* Para este proposito primeramente se necesita analizar las variables del dataframe y posteriormente filtrar por los datos que se necesitan predecir, para poder así hacer una correcta limpieza de los datos importantes

# Analisis de variables
"""

df_usuarios.shape

df_egresos.shape

df_cronicos.shape

"""## Analisis variables usuarios"""

df_usuarios.columns

"""## Analisis variables cronicos"""

df_cronicos.columns

df_cronicos['NombreDiagnostico36'].unique()

df_cronicos['Diagnostico36'].unique()

"""Se observa que para el nombre diagnostico y diagnostico se utilizan los nombres y el codigo que represanta a cada uno, pero para las predicciones esto puede afectar, por lo que se podría evaluar tranformar el diagnositco a numero y sumarlos y eliminar el nombre

## Analisis variables egresos
"""

df_egresos.columns

df_egresos['EPS VALIDADA'].unique()

"""Se observa que en esta base de datos se pueden encontrar los pacientes de la 'NUEVA EPS S.A. PGP', la cual es el grupo al que vamos a realizar la predicción.

# Limpieza y transformación

* Se inicia primeramente estandarizando los datos y cambiando valores codificados para poder realizar luego el filtrado de los datos a trabajar

## Se crea una copia de los dataframe y se asignan un unico formato a las columnas y datos de los data frame
"""

#Se crea una copia del dataframe para realizar cambios
df_cronico_cod = df_cronicos.copy()
df_usuarios_cod = df_usuarios.copy()
df_egresos_cod = df_egresos.copy()

"""Ya que el dataframe presenta caracteres codificados y estos dificultan la lectura se procede a remplazarlos"""

#Se remplazan los caracteres codificados
df_cronico_cod.columns = map(a.eliminar_caracteres_codificados, df_cronico_cod.columns)
df_usuarios_cod.columns = map(a.eliminar_caracteres_codificados, df_usuarios_cod.columns)
df_egresos_cod.columns = map(a.eliminar_caracteres_codificados, df_egresos_cod.columns)
print(df_cronico_cod.columns, '\n\n' ,df_usuarios_cod.columns, '\n\n' ,df_egresos_cod.columns)

#Se ponen en mayusculas las columnas
df_cronico_cod.columns = map(str.upper, df_cronico_cod.columns)
df_usuarios_cod.columns = map(str.upper, df_usuarios_cod.columns)
df_egresos_cod.columns = map(str.upper, df_egresos_cod.columns)
print(df_cronico_cod.columns, '\n\n' ,df_usuarios_cod.columns, '\n\n' ,df_egresos_cod.columns)

#Se ponen minusculas y la primera letra en mayuscula de los valores de las variables de la base de datos
df_cronico_cod = df_cronico_cod.applymap(a.eliminar_caracteres_codificados)
df_cronico_cod = df_cronico_cod.applymap(lambda x: x if not isinstance(x, str) else x.capitalize())

df_usuarios_cod = df_usuarios_cod.applymap(a.eliminar_caracteres_codificados)
df_usuarios_cod = df_usuarios_cod.applymap(lambda x: x if not isinstance(x, str) else x.capitalize())

df_egresos_cod = df_egresos_cod.applymap(a.eliminar_caracteres_codificados)
df_egresos_cod = df_egresos_cod.applymap(lambda x: x if not isinstance(x, str) else x.capitalize())

"""## Se analizan las variables que son necesarias para los dataframe"""

df_cronico_cod

df_usuarios_cod

df_egresos_cod

df_cronico_cod['NRODOC'].unique()

"""* Se evalua cuantas veces se repite un dato para validar si se puede añadir a la base de datos y en caso de que no se repita casi o no se repita ni una sola vez se elimina"""

from collections import Counter
# Usa Counter para contar las ocurrencias de cada valor
conteo = Counter(df_cronico_cod['INGRESO'])
cantidad_sum=0
# Imprime el resultado
for valor, cantidad in conteo.items():
  if cantidad >= 2:
    print(f'El valor {valor} se repite {cantidad} veces.')
    cantidad_sum = cantidad + cantidad_sum
print(cantidad_sum)

df_egresos_cod['EPS VALIDADA'][df_egresos_cod['EPS VALIDADA'] == 'Nueva eps s.a. pgp']

df_egresos_cod['MODALIDAD CONTRATO'][df_egresos_cod['MODALIDAD CONTRATO'] == 'Pgp']

"""Se filtran las bases de datos en los años en comun"""

#Se selecciona unicamente los años 2018 y 2021 ya que son los años que se tienen en comuna y el año 2017 no se cuenta porque solamente cuenta con el mes de diciembre
años_filtrar = [2018, 2021]
df_egresos_cod['YEAR'] = df_egresos_cod['YEAR'][df_egresos_cod['YEAR'].isin(años_filtrar)]
df_cronico_cod['YEAR'] = df_cronico_cod['YEAR'][df_cronico_cod['YEAR'].isin(años_filtrar)]
df_cronico_cod = df_cronico_cod.dropna(subset=['YEAR'])
df_egresos_cod = df_egresos_cod.dropna(subset=['YEAR'])
df_usuarios_cod['YEAR'] = df_usuarios_cod['YEAR'][df_usuarios_cod['YEAR'].isin(años_filtrar)]
df_usuarios_cod = df_usuarios_cod.dropna(subset=['YEAR'])

df_cronico_cod['YEAR'] = df_cronico_cod['YEAR'].astype(int)
df_egresos_cod['YEAR'] = df_egresos_cod['YEAR'].astype(int)

df_cronico_cod.head()

df_egresos_cod.sort_values('YEAR')

df_cronico_cod['YEAR'].unique()

df_egresos_cod['YEAR'].unique()

"""Se pueden eliminar:
* # Son las columnas a eliminar ya que se consideran pueden generar problemas al unir los df
eliminar_egresos = [ 'EPS VALIDADA' , 'NRO ATENCION', 'NRO INGRESO', 'SERVICIO HABILITADO COD', 'TIPO IDENTIFICACION', 'FECHA NACIMIENTO', 'EPS VALIDADA', 'BLOQUE', 'PISO',
'NRO CAMA', 'FECHA INGRESO SERVICIO', 'FECHA POSIBLE ALTA', 'FECHA ALTA MEDICA', 'FECHA RECAUDO', 'FECHA CAMILLERO',	'FECHA ENFERMERIA',	'FECHA FACTURACION AUDIFARMA',
'FECHA FARMACIA',	'FECHA ASEO', 'DXPRINCIPAL EGRESO COD', 'DXPRINCIPAL EGRESO', 'DX RELACIONADO1', 'DX RELACIONADO2', 'DX RELACIONADO3']

* eliminar_usuario = ['QUINQUENIO','ULTIMA CLASE FUNCIONAL','PRIMERA CLASE FUNCIONAL','MES', 'FECHA NACIMIENTO', 'DEPARTAMENTO', 'MUNICIPIO', 'BARRIO', 'FECHA INICIO AL PGP', 'FECHA PRIMERA CLASE FUNCIONAL',
'FECHA ULTIMA CLASE FUNCIONAL']

* eliminar_cronico = [ 'MES', 'YEAR', 'FECHA DILIGENCIAMIENTO', 'HORA', 'IMC', 'FECHA GLICEMIA', 'FECHA HEMOGLOBINA GLICOSILADA', 'FECHA LDL', 'FECHA HDL', 'FECHA COLESTEROL TOTAL', 'FECHA TRIGLICERIDOS', 'FECHA CREATININA1',
'FECHA MICROALBUMINURIA', 'FECHA CREATININA2', 'FECHA BASCILOSCOPIA', 'FECHA VACUNA NEUMOCOCO', 'FECHA VACUNA NEUMOCOCO VEINTITRES VALENTES', 'FECHA PROXIMO CONTROL', 'FECHA CITA MORBILIDAD']

"""

df_usuarios_cod.columns

# Son las columnas a eliminar ya que se consideran pueden generar problemas al unir los df
eliminar_egresos = [ 'EPS VALIDADA' , 'NRO ATENCION', 'NRO INGRESO', 'SERVICIO HABILITADO COD', 'TIPO IDENTIFICACION', 'FECHA NACIMIENTO', 'EPS VALIDADA', 'BLOQUE', 'PISO',
                    'NRO CAMA', 'FECHA INGRESO SERVICIO', 'FECHA POSIBLE ALTA', 'FECHA ALTA MEDICA', 'FECHA RECAUDO', 'FECHA CAMILLERO',	'FECHA ENFERMERIA',	'FECHA FACTURACION AUDIFARMA',
                     'FECHA FARMACIA',	'FECHA ASEO', 'DXPRINCIPAL EGRESO COD', 'DXPRINCIPAL EGRESO', 'DX RELACIONADO1', 'DX RELACIONADO2', 'DX RELACIONADO3']

eliminar_usuario = ['QUINQUENIO','ULTIMA CLASE FUNCIONAL','PRIMERA CLASE FUNCIONAL','MES', 'FECHA NACIMIENTO', 'DEPARTAMENTO', 'MUNICIPIO', 'BARRIO', 'FECHA INICIO AL PGP', 'FECHA PRIMERA CLASE FUNCIONAL',
                                      'FECHA ULTIMA CLASE FUNCIONAL']

eliminar_cronico = [ 'MES', 'YEAR', 'FECHA DILIGENCIAMIENTO', 'HORA', 'IMC', 'FECHA GLICEMIA', 'FECHA HEMOGLOBINA GLICOSILADA', 'FECHA LDL', 'FECHA HDL', 'FECHA COLESTEROL TOTAL', 'FECHA TRIGLICERIDOS', 'FECHA CREATININA1',
                    'FECHA MICROALBUMINURIA', 'FECHA CREATININA2', 'FECHA BASCILOSCOPIA', 'FECHA VACUNA NEUMOCOCO', 'FECHA VACUNA NEUMOCOCO VEINTITRES VALENTES', 'FECHA PROXIMO CONTROL', 'FECHA CITA MORBILIDAD']

#Ejecutar esto solo una vez
df_egresos_cod = df_egresos_cod.drop(eliminar_egresos, axis=1)
df_usuarios_cod = df_usuarios_cod.drop(eliminar_usuario, axis=1)
df_cronico_cod = df_cronico_cod.drop(eliminar_cronico, axis=1)

df_egresos_cod = df_egresos_cod[df_egresos_cod['MODALIDAD CONTRATO']=='Pgp']

df_egresos_cod

"""Se filtra la base de datos de usuarios"""

df_usuarios_cod.columns

df_usuarios_cod['YEAR'].unique()

df_usuarios_cod=df_usuarios_cod.drop(['YEAR'],axis=1) # se eliminaron estas variables debido a que teniamos la clase funcional actual y estaba completa

df_usuarios_cod=df_usuarios_cod.sort_values(by='EDAD', ascending=False)

df_usuarios_cod = df_usuarios_cod.drop_duplicates(subset=['NRODOC'])

df_usuarios_cod

"""##Unión de datos

* Una vez se cambiaron las columnas y los datos por a una forma estandar se puede realizar la union de las bases de datos
"""

df_egresos_cod.shape

df_cronico_cod.shape

# Conociendo los codigos por los cuales se pueden realizar la union de los dataframe(df) se procede a unir, teniendo encuenta que la variable
# en comun es el'NRODOC'.
df_resultado = pd.merge(pd.merge(df_egresos_cod, df_cronico_cod, on='NRODOC', how='right'), df_usuarios_cod, on='NRODOC', how='inner')

#Conociendo los codigos por los cuales se pueden realizar la union de los dataframe(df) se procede a unir, teniendo encuenta que la variable
#en comun es el'NRODOC'.
# df_resultado = pd.merge(pd.merge(df_cronico_cod, df_usuarios_cod, on='NRODOC', how='left'), df_egresos_cod, on='NRODOC', how='left')

df_resultado = df_resultado[df_resultado['MODALIDAD CONTRATO']=='Pgp']

df_egresos_cod.shape

df_usuarios_cod.shape

df_cronico_cod.shape

df_resultado.shape

df_resultado = df_resultado.drop_duplicates()

df_resultado.shape

"""## Análisis de nulos de datos totales"""

df_resultado.tail()

df_resultado.shape

df_resultado.rename(columns={"MES_x":"MES HOSPITALIZACION", "MES_y":"MES CIRUGIAS", 'YEAR_x':"AÑO HOSPITALIZACION", 'YEAR_y':"AÑO CIRUGIAS"  }, inplace=True)

df_resultado.columns.get_loc("DIAGNOSTICO1")
df_resultado.columns.get_loc("NOMBREDIAGNOSTICO83")

#Ejecutar esto solo 1 vez, esto suma la cantidad de valores que hay no nulos en las columnas diagnostico 1 en adelante
df_resultado["CANTIDAD DE DIAGNOSTICOS"] =  ((df_resultado.iloc[:,df_resultado.columns.get_loc("DIAGNOSTICO1"):df_resultado.columns.get_loc("NOMBREDIAGNOSTICO83")].count(axis=1))/2).astype(int)

df_resultado["CANTIDAD DE DIAGNOSTICOS"]

"""Se realiza un analisis más profundo de los datos que contiene estas variables con nulos"""

df_resultado.drop(columns= df_resultado.iloc[:,df_resultado.columns.get_loc("DIAGNOSTICO1"):df_resultado.columns.get_loc("NOMBREDIAGNOSTICO83")+1].columns,inplace=True) #Sólo ejecutar una vez, sino PAILA

df_resultado

"""Hay que tratar las variables objetivos de estancia hospitalaria, la cual es la resta entre 'FECHA SALIDA' - 'FECHA INGRESO CLINICA'"""

for columna, tipo in df_resultado.dtypes.items():
    print(f"{columna}: {tipo}")

"""Se convierten los datos de fecha de object a fecha"""

df_resultado['FECHA INGRESO CLINICA'].isnull().sum()

df_resultado['FECHA SALIDA'].isnull().sum()

# FECHA INGRESO CLINICA: object
# FECHA SALIDA: object

df_resultado['FECHA INGRESO CLINICA'] = pd.to_datetime(df_resultado['FECHA INGRESO CLINICA'], format="%Y-%m-%d %H:%M:%S.%f")
df_resultado['FECHA SALIDA'] = pd.to_datetime(df_resultado['FECHA SALIDA'], format="%Y-%m-%d %H:%M:%S.%f")

df_resultado['FECHA INGRESO CLINICA'].info()
df_resultado['FECHA SALIDA'].info()

df_resultado['TIEMPO ESTANCIA'] = (df_resultado['FECHA SALIDA'] - df_resultado['FECHA INGRESO CLINICA']).dt.total_seconds() / 3600  # 3600 segundos en una hora

df_resultado = df_resultado.drop(['FECHA SALIDA', 'FECHA INGRESO CLINICA'], axis=1)

df_resultado

df_resultado = df_resultado.drop_duplicates(subset=['NRODOC', 'TIEMPO ESTANCIA'])

df_resultado.shape

df_resultado['YEAR'] = df_resultado['YEAR'].astype(int)

# df_resultado['FECHA'] = df_resultado['YEAR'].str.cat(df_resultado['MES'], sep='-')

df_resultado.sort_values('YEAR')

df_resultado['EDAD'].isnull().sum()

df_resultado['CICLO_VITAL'].isnull().sum()

df_resultado['YEAR'] = df_resultado['YEAR'].astype(int)

meses_a_numero = {
    "Enero": 1,
    "Febrero": 2,
    "Marzo": 3,
    "Abril": 4,
    "Mayo": 5,
    "Junio": 6,
    "Julio": 7,
    "Agosto": 8,
    "Septiembre": 9,
    "Octubre": 10,
    "Noviembre": 11,
    "Diciembre": 12
}

df_resultado['MES'] = df_resultado['MES'].map(meses_a_numero)

df_resultado['FECHA'] = pd.to_datetime(df_resultado['YEAR'].astype(str) + '-' + df_resultado['MES'].astype(str), format='%Y-%m')

# Crea una nueva columna 'FECHA_SIN_DIA' con solo el año y el mes
df_resultado['FECHA'] = df_resultado['FECHA'].dt.to_period('M')

df_resultado = df_resultado.drop(['YEAR', 'MES'], axis=1)

df_resultado.sort_values('FECHA')

for i in df_resultado.columns.to_list():
  print(i)













#Se analizan las variables con datos nulos
nulos = df_resultado.isnull().sum()
nulos = nulos[nulos>0]
nulos

df_resultado

analisis_nulos = df_resultado.isnull().sum()

analisis_nulos[analisis_nulos>0].index

nulos = analisis_nulos[analisis_nulos>0].values
nulos

contador = 0
for i in analisis_nulos[analisis_nulos>0].index:
  print(i, "=", round(nulos[contador]/df_resultado.shape[0], 3))
  contador+=1

df_resultado.shape

contador = 0
variables_eliminar = []
for i in analisis_nulos[analisis_nulos>0].index:
  if round(nulos[contador]/df_resultado.shape[0], 3) >= 0.18:
    variables_eliminar.append(i)
  contador+=1
variables_eliminar

len(variables_eliminar)

df_resultado.drop(columns= variables_eliminar,inplace=True)

df_resultado.shape

# for i in analisis_nulos[analisis_nulos>0].index:
#   print(i, "\n", df_resultado[i].unique())

# analisis_nulos = df_resultado.isnull().sum()
# nulos = analisis_nulos[analisis_nulos>0].values
# nulos

contador = 0
nulos_eliminar = []
for i in analisis_nulos[analisis_nulos>0].index:
  if round(nulos[contador]/df_resultado.shape[0], 3) <= 0.05:
    nulos_eliminar.append(i)
  contador+=1
nulos_eliminar

len(nulos_eliminar)

df_resultado.dropna(subset=nulos_eliminar, inplace=True)

df_resultado.shape

analisis_nulos = df_resultado.isnull().sum()
nulos = analisis_nulos[analisis_nulos>0].values
nulos

for i in analisis_nulos[analisis_nulos>0].index:
  print(i, "\n", df_resultado[i].unique())

variables_object = df_resultado.select_dtypes(include=['object']).columns
df_resultado[variables_object] = df_resultado[variables_object].fillna(value="No aplica")

df_resultado = df_resultado.applymap(lambda x: 'No aplica' if x == 'Nd' else x)

df_resultado["TIPO DIABETES MELLITUS"].unique()

analisis_nulos = df_resultado.isnull().sum()
nulos = analisis_nulos[analisis_nulos>0].values
for i in analisis_nulos[analisis_nulos>0].index:
  print(i, "\n", df_resultado[i].unique())

# df_resultado["AÑOS DE CONSUMO"].fillna(value=0, inplace=True)

analisis_nulos = df_resultado.isnull().sum()
nulos = analisis_nulos[analisis_nulos>0]
nulos

contador = 0
for i in df_resultado.dtypes.index:
  print(i,"",df_resultado.dtypes.values[contador])
  contador += 1

df_resultado_corr = df_resultado.select_dtypes(include=[float, int])  # Seleccionar solo columnas numéricas
correlacion = df_resultado_corr.corr()


# Definir el umbral de correlación (0.80 en este caso)
umbral_correlacion = 0.65

# Encontrar y mostrar las pares de variables con correlación igual o superior al umbral
print("Pares de variables con correlación igual o superior a", umbral_correlacion)
for i in range(len(correlacion.columns)):
    for j in range(i):
        correla = correlacion.iloc[i, j]
        variable1 = correlacion.columns[i]
        variable2 = correlacion.columns[j]
        if abs(correla) >= umbral_correlacion:
            print(f"{variable1} - {variable2}: {correla:.2f}")

df_resultado.head()

variables_eliminar = ["TIPO", "INGRESO", "ATENCION","VO2 - MAXIMA CANTIDAD DE OXIGENO", "SUMATORIA PLIEGUES", "CONSTANTES",
                      "FUENTE FINANCIACION1","FUENTE FINANCIACION2", "MODALIDAD CONTRATO", "PISO ANTERIOR", "NRO CAMA ANTERIOR",
                      "MODALIDAD CONTRATO", "ANALISIS Y CONDUCTA A SEGUIR"]

df_resultado.drop(columns= variables_eliminar, inplace=True)

df_resultado['DEMORA APLICACION MEDICAMENTO'] = df_resultado['DEMORA APLICACION MEDICAMENTO'].str.split(':').str[0]

# Convertir los valores de minutos a números enteros
df_resultado['DEMORA APLICACION MEDICAMENTO'] = df_resultado['DEMORA APLICACION MEDICAMENTO'].astype(int)
#valor absoluto
df_resultado['DEMORA APLICACION MEDICAMENTO'] = df_resultado['DEMORA APLICACION MEDICAMENTO'].abs()

df_resultado['DEMORA ASIGNACION CAMA'] = df_resultado['DEMORA ASIGNACION CAMA'].str.split(':').str[0]

# Convertir los valores de minutos a números enteros
df_resultado['DEMORA ASIGNACION CAMA'] = df_resultado['DEMORA ASIGNACION CAMA'].astype(int)

df_resultado["TIEMPO CON EL DIAGNOSTICO"] = df_resultado["TIEMPO CON EL DIAGNOSTICO"].replace("No aplica", 0)
df_resultado["TIEMPO CON EL DIAGNOSTICO1"] = df_resultado["TIEMPO CON EL DIAGNOSTICO1"].replace("No aplica", 0)
df_resultado["CUANTOS CIGARRILLOS DIA"] = df_resultado["CUANTOS CIGARRILLOS DIA"].replace("No aplica", 0)
df_resultado["TIEMPO CON EL DIAGNOSTICO1"] = df_resultado["TIEMPO CON EL DIAGNOSTICO1"].astype("int")
df_resultado["TIEMPO CON EL DIAGNOSTICO"] = df_resultado["TIEMPO CON EL DIAGNOSTICO"].astype("int")
df_resultado["CUANTOS CIGARRILLOS DIA"] = df_resultado["CUANTOS CIGARRILLOS DIA"].astype("int")

df_resultado["FECHA"] = df_resultado["FECHA"].dt.to_timestamp()

dtale.show(df_resultado) #Se crea un dtale, este permite hacer una mejor exploracion de los datos, aplicando filtros, graficos

# # Guardar el DataFrame en un archivo CSV
# df_resultado.to_csv('datos_resultado.csv', index=False)